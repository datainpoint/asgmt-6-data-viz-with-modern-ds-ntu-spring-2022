{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Data Visualization with Modern Data Science\n",
    "\n",
    "> Assignment 6\n",
    "\n",
    "Yao-Jen Kuo <yaojenkuo@ntu.edu.tw> from [DATAINPOINT](https://www.datainpoint.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Instructions\n",
    "\n",
    "- Due to reduced capacity of mybinder.org, we use Google Colab instead.\n",
    "- Save a copy for consistency by clicking the `Copy to Drive` button.\n",
    "- If you accidentally delete some of the cells, just re-click the assignment link again for the original notebook.\n",
    "- Write down your solution between comments `### BEGIN SOLUTION` and `### END SOLUTION`.\n",
    "- Running tests to see if your solutions are right:\n",
    "    - Connect.\n",
    "    - Runtime -> Restart and run all -> Yes -> Run anyway.\n",
    "    - Scroll down to the bottom of notebook to see the test result.\n",
    "- When you are ready to submit, click File -> Download .py.\n",
    "- Rename the exported Python script with your student ID(e.g. `b01234567.py`) and upload to the Assignment session on NTU COOL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -N \"https://raw.githubusercontent.com/datainpoint/asgmt-6-data-viz-with-modern-ds-ntu-spring-2022/main/UID_ISO_FIPS_LookUp_Table.csv\"\n",
    "!wget -N \"https://raw.githubusercontent.com/datainpoint/asgmt-6-data-viz-with-modern-ds-ntu-spring-2022/main/05-16-2022.csv\"\n",
    "!wget -N \"https://raw.githubusercontent.com/datainpoint/asgmt-6-data-viz-with-modern-ds-ntu-spring-2022/main/imdb_top250.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. Define a Python function named `import_lookup_table_and_daily_report()` which imports `UID_ISO_FIPS_LookUp_Table.csv` and `05-16-2022.csv` in working directory.\n",
    "\n",
    "- Expected inputs: None.\n",
    "- Expected outputs: `tuple`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_lookup_table_and_daily_report() -> tuple:\n",
    "    \"\"\"\n",
    "    >>> lookup_table, daily_report = import_lookup_table_and_daily_report()\n",
    "    >>> type(lookup_table)\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> type(daily_report)\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> lookup_table.shape\n",
    "    (4317, 12)\n",
    "    >>> daily_report.shape\n",
    "    (4011, 14)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. Define a Python function named `inner_join_lookup_table_and_daily_report()` which inner joins `UID_ISO_FIPS_LookUp_Table.csv` and `05-16-2022.csv` on `Combined_Key` in working directory. Select specified columns from the joined result.\n",
    "\n",
    "- Expected inputs: None.\n",
    "- Expected outputs: `pandas.core.frame.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_join_lookup_table_and_daily_report() -> pd.core.frame.DataFrame:\n",
    "    \"\"\"\n",
    "    >>> lookup_table_and_daily_report = inner_join_lookup_table_and_daily_report()\n",
    "    >>> type(lookup_table_and_daily_report)\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> lookup_table_and_daily_report.shape\n",
    "    (4009, 9)\n",
    "    >>> print(lookup_table_and_daily_report)\n",
    "              Admin2 Province_State Country_Region             Combined_Key  \\\n",
    "    0            NaN            NaN    Afghanistan              Afghanistan   \n",
    "    1            NaN            NaN        Albania                  Albania   \n",
    "    2            NaN            NaN     Antarctica               Antarctica   \n",
    "    3            NaN            NaN        Algeria                  Algeria   \n",
    "    4            NaN            NaN        Andorra                  Andorra   \n",
    "    ...          ...            ...            ...                      ...   \n",
    "    4004  Sweetwater        Wyoming             US  Sweetwater, Wyoming, US   \n",
    "    4005       Teton        Wyoming             US       Teton, Wyoming, US   \n",
    "    4006       Uinta        Wyoming             US       Uinta, Wyoming, US   \n",
    "    4007    Washakie        Wyoming             US    Washakie, Wyoming, US   \n",
    "    4008      Weston        Wyoming             US      Weston, Wyoming, US   \n",
    "\n",
    "          Confirmed  Deaths  Population  Incident_Rate  Case_Fatality_Ratio  \n",
    "    0        179321    7691  38928341.0     460.643828             4.288957  \n",
    "    1        275621    3497   2877800.0    9577.489749             1.268771  \n",
    "    2            11       0         NaN            NaN             0.000000  \n",
    "    3        265823    6875  43851043.0     606.195387             2.586307  \n",
    "    4         42156     153     77265.0   54560.279557             0.362938  \n",
    "    ...         ...     ...         ...            ...                  ...  \n",
    "    4004      11088     126     42343.0   26186.146470             1.136364  \n",
    "    4005      10074      16     23464.0   42933.856120             0.158825  \n",
    "    4006       5643      39     20226.0   27899.733017             0.691122  \n",
    "    4007       2359      44      7805.0   30224.215247             1.865197  \n",
    "    4008       1588      18      6927.0   22924.787065             1.133501  \n",
    "\n",
    "    [4009 rows x 9 columns]\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. Define a Python function named `create_combined_keys()` which replicate the column `Combined_Key` but concatenating `Country_Region`, `Province_State`, and `Admin2` with different order and a different separator `-` from the output of `inner_join_lookup_table_and_daily_report()`.\n",
    "\n",
    "- Expected inputs: None.\n",
    "- Expected outputs: `pandas.core.series.Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_keys() -> pd.core.series.Series:\n",
    "    \"\"\"\n",
    "    >>> combined_keys = create_combined_keys()\n",
    "    >>> type(combined_keys)\n",
    "    pandas.core.series.Series\n",
    "    >>> combined_keys.shape\n",
    "    (4009,)\n",
    "    >>> combined_keys\n",
    "    0                 Afghanistan\n",
    "    1                     Albania\n",
    "    2                  Antarctica\n",
    "    3                     Algeria\n",
    "    4                     Andorra\n",
    "                    ...          \n",
    "    4004    US-Wyoming-Sweetwater\n",
    "    4005         US-Wyoming-Teton\n",
    "    4006         US-Wyoming-Uinta\n",
    "    4007      US-Wyoming-Washakie\n",
    "    4008        US-Wyoming-Weston\n",
    "    Name: Country_Region, Length: 4009, dtype: object\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. Define a Python function named `calculate_incident_rate_by_country_region()` which replicate the column `Incident_Rate` from the output of `inner_join_lookup_table_and_daily_report()` but calculate in country-level.\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Incident Rate} = \\frac{\\text{Confirmed}}{\\text{Population}} \\times 100000\n",
    "\\end{equation}\n",
    "\n",
    "PS Exclude data with 0 population.\n",
    "\n",
    "- Expected inputs: None.\n",
    "- Expected outputs: `pandas.core.series.Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_incident_rate_by_country_region() -> pd.core.series.Series:\n",
    "    \"\"\"\n",
    "    >>> incident_rate_by_country_region = calculate_incident_rate_by_country_region()\n",
    "    >>> type(incident_rate_by_country_region)\n",
    "    pandas.core.series.Series\n",
    "    >>> incident_rate_by_country_region.shape\n",
    "    (194,)\n",
    "    >>> incident_rate_by_country_region\n",
    "    Country_Region\n",
    "    Afghanistan             460.643828\n",
    "    Albania                9577.489749\n",
    "    Algeria                 606.195387\n",
    "    Andorra               54560.279557\n",
    "    Angola                  302.093928\n",
    "                              ...     \n",
    "    Vietnam               10990.688040\n",
    "    West Bank and Gaza    12885.226376\n",
    "    Yemen                    39.626543\n",
    "    Zambia                 1744.347082\n",
    "    Zimbabwe               1678.209144\n",
    "    Length: 194, dtype: float64\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. Define a Python function named `find_countries_incident_rate()` which retrieves the data given a `country_list` from the output of `calculate_incident_rate_by_country_region()`.\n",
    "\n",
    "```python\n",
    "country_list = [\"US\", \"United Kingdom\", \"France\", \"Germany\", \"Canada\", \"Korea, South\", \"Japan\", \"Singapore\", \"Australia\", \"Taiwan*\", \"New Zealand\"]\n",
    "```\n",
    "\n",
    "- Expected inputs: None.\n",
    "- Expected outputs: `pandas.core.series.Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_countries_incident_rate() -> pd.core.series.Series:\n",
    "    \"\"\"\n",
    "    >>> countries_incident_rate = find_countries_incident_rate()\n",
    "    >>> type(countries_incident_rate)\n",
    "    pandas.core.series.Series\n",
    "    >>> countries_incident_rate.shape\n",
    "    (11,)\n",
    "    >>> countries_incident_rate\n",
    "    Country_Region\n",
    "    Taiwan*            3486.017733\n",
    "    Japan              6651.047785\n",
    "    Canada            10036.393768\n",
    "    Singapore         21199.321134\n",
    "    New Zealand       22029.356414\n",
    "    US                24860.092964\n",
    "    Australia         26329.041583\n",
    "    Germany           31048.518279\n",
    "    United Kingdom    33336.954174\n",
    "    Korea, South      34778.063462\n",
    "    France            43126.260411\n",
    "    dtype: float64\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06. Define a Python function named `calculate_case_fatality_ratio_by_country_region()` which replicate the column `Case_Fatality_Ratio` from the output of `inner_join_lookup_table_and_daily_report()` but calculate in country-level.\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Case Fatality Ratio} = \\frac{\\text{Deaths}}{\\text{Confirmed}} \\times 100\n",
    "\\end{equation}\n",
    "\n",
    "- Expected inputs: None.\n",
    "- Expected outputs: `pandas.core.series.Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_case_fatality_ratio_by_country_region() -> pd.core.series.Series:\n",
    "    \"\"\"\n",
    "    >>> case_fatality_ratio_by_country_region = calculate_case_fatality_ratio_by_country_region()\n",
    "    >>> type(case_fatality_ratio_by_country_region)\n",
    "    pandas.core.series.Series\n",
    "    >>> case_fatality_ratio_by_country_region.shape\n",
    "    (199,)\n",
    "    >>> case_fatality_ratio_by_country_region\n",
    "    Country_Region\n",
    "    Afghanistan              4.288957\n",
    "    Albania                  1.268771\n",
    "    Algeria                  2.586307\n",
    "    Andorra                  0.362938\n",
    "    Angola                   1.913644\n",
    "                              ...    \n",
    "    West Bank and Gaza       0.860604\n",
    "    Winter Olympics 2022     0.000000\n",
    "    Yemen                   18.182587\n",
    "    Zambia                   1.242048\n",
    "    Zimbabwe                 2.198604\n",
    "    Length: 199, dtype: float64\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07. Define a Python function named `unify_countries_ir_and_cfr()` which unifies the incident rate and case fatality given a `country_list`.\n",
    "\n",
    "```python\n",
    "country_list = [\"US\", \"United Kingdom\", \"France\", \"Germany\", \"Canada\", \"Korea, South\", \"Japan\", \"Singapore\", \"Australia\", \"Taiwan*\", \"New Zealand\"]\n",
    "```\n",
    "\n",
    "- Expected inputs: None.\n",
    "- Expected outputs: `pandas.core.frame.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_countries_ir_and_cfr() -> pd.core.frame.DataFrame:\n",
    "    \"\"\"\n",
    "    >>> countries_ir_and_cfr = unify_countries_ir_and_cfr()\n",
    "    >>> type(countries_ir_and_cfr)\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> countries_ir_and_cfr.shape\n",
    "    (11, 3)\n",
    "    >>> print(countrys_ir_and_cfr)\n",
    "        Country_Region  Incident_Rate  Case_Fatality_Ratio\n",
    "    0      New Zealand   22029.356414             0.087980\n",
    "    1        Singapore   21199.321134             0.110141\n",
    "    2        Australia   26329.041583             0.117435\n",
    "    3          Taiwan*    3486.017733             0.132128\n",
    "    4     Korea, South   34778.063462             0.133317\n",
    "    5            Japan    6651.047785             0.358545\n",
    "    6           France   43126.260411             0.505482\n",
    "    7          Germany   31048.518279             0.533395\n",
    "    8   United Kingdom   33336.954174             0.795450\n",
    "    9           Canada   10036.393768             1.049803\n",
    "    10              US   24860.092964             1.210265\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08. Define a Python function named `melt_countries_ir_cfr()` which transforms the output of `unify_countries_ir_and_cfr` from wide format to long format.\n",
    "\n",
    "- Expected inputs: None.\n",
    "- Expected outputs: `pandas.core.frame.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_countries_ir_cfr() -> pd.core.frame.DataFrame:\n",
    "    \"\"\"\n",
    "    >>> countries_ir_cfr_long = melt_countries_ir_cfr()\n",
    "    >>> type(countries_ir_cfr_long)\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> countries_ir_cfr_long.shape\n",
    "    (22, 3)\n",
    "    >>> print(countries_ir_cfr_long)\n",
    "        Country_Region             Variable         Value\n",
    "    0      New Zealand  Case_Fatality_Ratio      0.087980\n",
    "    1        Singapore  Case_Fatality_Ratio      0.110141\n",
    "    2        Australia  Case_Fatality_Ratio      0.117435\n",
    "    3          Taiwan*  Case_Fatality_Ratio      0.132128\n",
    "    4     Korea, South  Case_Fatality_Ratio      0.133317\n",
    "    5            Japan  Case_Fatality_Ratio      0.358545\n",
    "    6           France  Case_Fatality_Ratio      0.505482\n",
    "    7          Germany  Case_Fatality_Ratio      0.533395\n",
    "    8   United Kingdom  Case_Fatality_Ratio      0.795450\n",
    "    9           Canada  Case_Fatality_Ratio      1.049803\n",
    "    10              US  Case_Fatality_Ratio      1.210265\n",
    "    11         Taiwan*        Incident_Rate   3486.017733\n",
    "    12           Japan        Incident_Rate   6651.047785\n",
    "    13          Canada        Incident_Rate  10036.393768\n",
    "    14       Singapore        Incident_Rate  21199.321134\n",
    "    15     New Zealand        Incident_Rate  22029.356414\n",
    "    16              US        Incident_Rate  24860.092964\n",
    "    17       Australia        Incident_Rate  26329.041583\n",
    "    18         Germany        Incident_Rate  31048.518279\n",
    "    19  United Kingdom        Incident_Rate  33336.954174\n",
    "    20    Korea, South        Incident_Rate  34778.063462\n",
    "    21          France        Incident_Rate  43126.260411\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09. Define a Python function named `import_imdb_top250()` which imports `imdb_top250.csv` in working directory.\n",
    "\n",
    "- Expected inputs: None.\n",
    "- Expected outputs: `pandas.core.frame.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_imdb_top250() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    >>> imdb_top250 = import_imdb_top250()\n",
    "    >>> type(imdb_top250)\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> imdb_top250.shape\n",
    "    (250, 2)\n",
    "    >>> print(imdb_top250)\n",
    "                                 Rank & Title  IMDb Rating\n",
    "    0    1.  The Shawshank Redemption  (1994)          9.2\n",
    "    1               2.  The Godfather  (1972)          9.2\n",
    "    2             3.  The Dark Knight  (2008)          9.0\n",
    "    3      4.  The Godfather: Part II  (1974)          9.0\n",
    "    4                5.  12 Angry Men  (1957)          8.9\n",
    "    ..                                    ...          ...\n",
    "    245                 246.  Aladdin  (1992)          8.0\n",
    "    246                247.  The Help  (2011)          8.0\n",
    "    247    248.  Beauty and the Beast  (1991)          8.0\n",
    "    248      249.  Dances with Wolves  (1990)          8.0\n",
    "    249                  250.  Rififi  (1955)          8.0\n",
    "\n",
    "    [250 rows x 2 columns]\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Define a Python function named `tidy_imdb_top250()` that is able to tidy the dataframe obtained from the previous question into a desired format.\n",
    "\n",
    "- Expected inputs: None.\n",
    "- Expected outputs: `pandas.core.frame.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_imdb_top250() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    >>> tidied_imdb_top250 = tidy_imdb_top250()\n",
    "    >>> type(tidied_imdb_top250)\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> tidied_imdb_top250.shape\n",
    "    (250, 4)\n",
    "    >>> print(tidied_imdb_top250)\n",
    "         rank                     title release_year  rating\n",
    "    0       1  The Shawshank Redemption         1994     9.2\n",
    "    1       2             The Godfather         1972     9.2\n",
    "    2       3           The Dark Knight         2008     9.0\n",
    "    3       4    The Godfather: Part II         1974     9.0\n",
    "    4       5              12 Angry Men         1957     8.9\n",
    "    ..    ...                       ...          ...     ...\n",
    "    245   246                   Aladdin         1992     8.0\n",
    "    246   247                  The Help         2011     8.0\n",
    "    247   248      Beauty and the Beast         1991     8.0\n",
    "    248   249        Dances with Wolves         1990     8.0\n",
    "    249   250                    Rififi         1955     8.0\n",
    "\n",
    "    [250 rows x 4 columns]\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## End of assignment, ignore the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestAssignmentSix(unittest.TestCase):\n",
    "    def test_01_import_lookup_table_and_daily_report(self):\n",
    "        lookup_table, daily_report = import_lookup_table_and_daily_report()\n",
    "        self.assertIsInstance(lookup_table, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(lookup_table.shape, (4317, 12))\n",
    "        self.assertIsInstance(daily_report, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(daily_report.shape, (4011, 14))\n",
    "    def test_02_inner_join_lookup_table_and_daily_report(self):\n",
    "        lookup_table_and_daily_report = inner_join_lookup_table_and_daily_report()\n",
    "        self.assertIsInstance(lookup_table_and_daily_report, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(lookup_table_and_daily_report.shape, (4009, 9))\n",
    "    def test_03_create_combined_keys(self):\n",
    "        combined_keys = create_combined_keys()\n",
    "        self.assertIsInstance(combined_keys, pd.core.series.Series)\n",
    "        self.assertEqual(combined_keys.shape, (4009,))\n",
    "        self.assertIn(\"Afghanistan\", combined_keys.values)\n",
    "        self.assertIn(\"Albania\", combined_keys.values)\n",
    "        self.assertIn(\"US-Wyoming-Uinta\", combined_keys.values)\n",
    "        self.assertIn(\"US-Wyoming-Washakie\", combined_keys.values)\n",
    "        self.assertIn(\"US-Wyoming-Weston\", combined_keys.values)\n",
    "    def test_04_calculate_incident_rate_by_country_region(self):\n",
    "        incident_rate_by_country_region = calculate_incident_rate_by_country_region()\n",
    "        self.assertIsInstance(incident_rate_by_country_region, pd.core.series.Series)\n",
    "        self.assertEqual(incident_rate_by_country_region.shape, (194,))\n",
    "        self.assertIn(\"Afghanistan\", incident_rate_by_country_region.index)\n",
    "        self.assertIn(\"Albania\", incident_rate_by_country_region.index)\n",
    "        self.assertIn(\"Yemen\", incident_rate_by_country_region.index)\n",
    "        self.assertIn(\"Zambia\", incident_rate_by_country_region.index)\n",
    "        self.assertIn(\"Zimbabwe\", incident_rate_by_country_region.index)\n",
    "    def test_05_find_countries_incident_rate(self):\n",
    "        countries_incident_rate = find_countries_incident_rate()\n",
    "        self.assertIsInstance(countries_incident_rate, pd.core.series.Series)\n",
    "        self.assertEqual(countries_incident_rate.shape, (11,))\n",
    "        country_list = [\"US\", \"United Kingdom\", \"France\", \"Germany\", \"Canada\", \"Korea, South\", \"Japan\", \"Singapore\", \"Australia\", \"Taiwan*\", \"New Zealand\"]\n",
    "        for country in country_list:\n",
    "            self.assertIn(country, countries_incident_rate.index)\n",
    "    def test_06_calculate_case_fatality_ratio_by_country_region(self):\n",
    "        case_fatality_ratio_by_country_region = calculate_case_fatality_ratio_by_country_region()\n",
    "        self.assertIsInstance(case_fatality_ratio_by_country_region, pd.core.series.Series)\n",
    "        self.assertEqual(case_fatality_ratio_by_country_region.shape, (199,))\n",
    "        self.assertIn(\"Afghanistan\", case_fatality_ratio_by_country_region.index)\n",
    "        self.assertIn(\"Albania\", case_fatality_ratio_by_country_region.index)\n",
    "        self.assertIn(\"Yemen\", case_fatality_ratio_by_country_region.index)\n",
    "        self.assertIn(\"Zambia\", case_fatality_ratio_by_country_region.index)\n",
    "        self.assertIn(\"Zimbabwe\", case_fatality_ratio_by_country_region.index)\n",
    "    def test_07_unify_countries_ir_and_cfr(self):\n",
    "        countries_ir_and_cfr = unify_countries_ir_and_cfr()\n",
    "        self.assertIsInstance(countries_ir_and_cfr, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(countries_ir_and_cfr.shape, (11, 3))\n",
    "        country_list = [\"US\", \"United Kingdom\", \"France\", \"Germany\", \"Canada\", \"Korea, South\", \"Japan\", \"Singapore\", \"Australia\", \"Taiwan*\", \"New Zealand\"]\n",
    "        for country in country_list:\n",
    "            self.assertIn(country, countries_ir_and_cfr[\"Country_Region\"].values)\n",
    "    def test_08_melt_countries_ir_cfr(self):\n",
    "        countries_ir_cfr_long = melt_countries_ir_cfr()\n",
    "        self.assertIsInstance(countries_ir_cfr_long, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(countries_ir_cfr_long.shape, (22, 3))\n",
    "        country_list = [\"US\", \"United Kingdom\", \"France\", \"Germany\", \"Canada\", \"Korea, South\", \"Japan\", \"Singapore\", \"Australia\", \"Taiwan*\", \"New Zealand\"]\n",
    "        for country in country_list:\n",
    "            self.assertIn(country, countries_ir_cfr_long[\"Country_Region\"].unique())\n",
    "        self.assertIn(\"Case_Fatality_Ratio\", countries_ir_cfr_long.iloc[:, 1].unique())\n",
    "        self.assertIn(\"Incident_Rate\", countries_ir_cfr_long.iloc[:, 1].unique())\n",
    "    def test_09_import_imdb_top250(self):\n",
    "        imdb_top250 = import_imdb_top250()\n",
    "        self.assertIsInstance(imdb_top250, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(imdb_top250.shape, (250, 2))\n",
    "    def test_10_tidy_imdb_top250(self):\n",
    "        tidied_imdb_top250 = tidy_imdb_top250()\n",
    "        self.assertIsInstance(tidied_imdb_top250, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(tidied_imdb_top250.shape, (250, 4))\n",
    "        self.assertIn(\"The Shawshank Redemption\", tidied_imdb_top250.iloc[:, 1].values)\n",
    "        self.assertIn(\"The Godfather\", tidied_imdb_top250.iloc[:, 1].values)\n",
    "        self.assertIn(\"The Dark Knight\", tidied_imdb_top250.iloc[:, 1].values)\n",
    "        self.assertIn(\"Beauty and the Beast\", tidied_imdb_top250.iloc[:, 1].values)\n",
    "        self.assertIn(\"Dances with Wolves\", tidied_imdb_top250.iloc[:, 1].values)\n",
    "        self.assertEqual(tidied_imdb_top250.iloc[:, 0].nunique(), 250)\n",
    "        \n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestAssignmentSix)\n",
    "runner = unittest.TextTestRunner(verbosity=2)\n",
    "test_results = runner.run(suite)\n",
    "number_of_failures = len(test_results.failures)\n",
    "number_of_errors = len(test_results.errors)\n",
    "number_of_test_runs = test_results.testsRun\n",
    "number_of_successes = number_of_test_runs - (number_of_failures + number_of_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"You've got {} successes among {} questions.\".format(number_of_successes, number_of_test_runs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
